{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a3fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"../../results/evaluate_50_log0606_00_int.csv\"\n",
    "log_folder = \"../../experiments/0606_00_int/\"\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "df = pd.read_csv(file_name, sep=\",\")\n",
    "df.columns = [\n",
    "    \"machine_time\", \"timestamp\", \"person_id\", \"route_type\", \"moving_id\", \"late_time\"\n",
    "]\n",
    "# remove the first row\n",
    "df = df.iloc[1:]\n",
    "\n",
    "# name the route_type\n",
    "_route_type_map = {\n",
    "    0: \"T1/Tram\",\n",
    "    1: \"Metro\",\n",
    "    3: \"Bus\",\n",
    "    6: \"Teleo\"\n",
    "}\n",
    "\n",
    "df[\"route_type_name\"] = df[\"route_type\"].map(_route_type_map)\n",
    "\n",
    "df['datetime'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "df = df[df['datetime'] < datetime.datetime(2025, 5, 17)]\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee94d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode Shape per timestep\n",
    "\n",
    "df['datetime'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "df['time_bin'] = df['datetime'].dt.floor('24H')\n",
    "# df = df[df['time_bin'] <= \"2025-05-15 00:00:00\"]\n",
    "\n",
    "dedup_df = df.drop_duplicates(subset=['time_bin', 'person_id', 'route_type_name'])\n",
    "route_counts = dedup_df.groupby(['time_bin', 'route_type_name'])['person_id'].nunique().reset_index(name='person_count')\n",
    "\n",
    "# total_persons = dedup_df.groupby('time_bin')['person_id'].nunique().reset_index(name='total_unique_persons')\n",
    "total_counts = route_counts.groupby('time_bin')['person_count'].sum().reset_index(name='total_count')\n",
    "\n",
    "result = pd.merge(route_counts, total_counts, on='time_bin')\n",
    "result['ratio'] = result['person_count'] / result['total_count']\n",
    "\n",
    "# remove last row\n",
    "result = result[result['time_bin'] != result['time_bin'].max()]\n",
    "\n",
    "# print(result.head())\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pivot = result.pivot(index='time_bin', columns='route_type_name', values='ratio').fillna(0)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "pivot.plot(kind='bar', stacked=False, ax=plt.gca(), colormap='tab20')\n",
    "\n",
    "plt.title('Mode Share per Timestep')\n",
    "# Format x-axis labels datetime to %Y-%m-%d\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Choice Ratio')\n",
    "plt.legend(title='Route Type')\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdab3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df['datetime'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "df['date'] = df['datetime'].dt.date\n",
    "\n",
    "person_day_movings = df.groupby(['date', 'person_id'])['moving_id'].apply(set).reset_index()\n",
    "\n",
    "person_day_movings = person_day_movings.sort_values(by=['person_id', 'date'])\n",
    "\n",
    "person_day_movings['prev_date'] = person_day_movings.groupby('person_id')['date'].shift(1)\n",
    "person_day_movings['prev_moving_id'] = person_day_movings.groupby('person_id')['moving_id'].shift(1)\n",
    "\n",
    "def has_common_moving_id(curr, prev):\n",
    "    if pd.isna(prev):\n",
    "        return False\n",
    "    # return len(curr & prev) == len(curr)\n",
    "    return set(curr) == set(prev)\n",
    "\n",
    "def ratio_change_moving_ids(curr, prev):\n",
    "    if pd.isna(prev):\n",
    "        return 0.0\n",
    "    return 1 - len(curr.intersection(prev)) / max(len(prev), len(curr))\n",
    "\n",
    "person_day_movings['same_trip_as_yesterday'] = person_day_movings.apply(\n",
    "    lambda row: has_common_moving_id(row['moving_id'], row['prev_moving_id']),\n",
    "    axis=1\n",
    ")\n",
    "person_day_movings['ratio_trip_change'] = person_day_movings.apply(\n",
    "    lambda row: ratio_change_moving_ids(row['moving_id'], row['prev_moving_id']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "result = person_day_movings.groupby('date').agg(\n",
    "    total_persons=('person_id', 'nunique'),\n",
    "    keep_same_trip=('same_trip_as_yesterday', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "result['ratio'] = (1-result['keep_same_trip'] / result['total_persons']) * 100\n",
    "\n",
    "print(result)\n",
    "\n",
    "# Draw the graph of ratio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "result['date'] = pd.to_datetime(result['date'])\n",
    "\n",
    "highlight = result['date'].isin([\n",
    "    datetime.datetime(2025, 5, 17),\n",
    "    datetime.datetime(2025, 5, 18),\n",
    "    datetime.datetime(2025, 5, 24),\n",
    "    datetime.datetime(2025, 5, 25),\n",
    "    datetime.datetime(2025, 5, 31)\n",
    "])\n",
    "\n",
    "sns.set_theme(style=\"ticks\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "# plt.plot(result['date'], result['ratio'], marker='o', linestyle='-')\n",
    "sns.lineplot(data=result, x='date', y='ratio', marker='o', color=\"#e74c3c\")\n",
    "plt.gca().set_xticks(result['date'])\n",
    "\n",
    "plt.scatter(\n",
    "    result.loc[highlight, 'date'],\n",
    "    result.loc[highlight, 'ratio'],\n",
    "    color='blue',\n",
    "    zorder=10,\n",
    "    label='Weekends',\n",
    ")\n",
    "\n",
    "plt.title('Change Rate in Personal Travel Plan Preferences')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Change Rate (%)')\n",
    "# plt.grid(True)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d112c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Chuyển timestamp sang datetime và lấy ngày\n",
    "df['datetime'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "df['date'] = df['datetime'].dt.date\n",
    "\n",
    "# Tính late_time max của mỗi moving_id\n",
    "moving_late = df.groupby('moving_id').agg(\n",
    "    max_late_time=('late_time', 'max'),\n",
    "    first_timestamp=('timestamp', 'min')\n",
    ").reset_index()\n",
    "\n",
    "# Gán date cho mỗi moving_id dựa vào timestamp đầu tiên\n",
    "moving_late['date'] = pd.to_datetime(moving_late['first_timestamp'], unit='s').dt.date\n",
    "\n",
    "# Tính average late_time mỗi ngày\n",
    "daily_avg_late = moving_late.groupby('date')['max_late_time'].mean().reset_index(name='avg_late_time')\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "daily_avg_late['date'] = pd.to_datetime(daily_avg_late['date'])\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(daily_avg_late['date'], daily_avg_late['avg_late_time'], marker='o')\n",
    "\n",
    "plt.title('Average Max Late Time per Day (over trip)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Avg arrival late time (seconds)')\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a739f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique moving_id per day\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Mode Shape per timestep\n",
    "\n",
    "df['datetime'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "df['time_bin'] = df['datetime'].dt.floor('24H')\n",
    "\n",
    "dedup_df = df.drop_duplicates(subset=['time_bin', 'person_id'])\n",
    "moving_counts = dedup_df.groupby(['time_bin'])['moving_id'].nunique().reset_index(name='moving_count')\n",
    "moving_counts.head()\n",
    "\n",
    "# Draw the bar chat\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(moving_counts['time_bin'], moving_counts['moving_count'], color='mediumseagreen')\n",
    "plt.title('Unique Trips per Day')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Total')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca70cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# People choose suboptimal route over time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "# Mode Shape per timestep\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "stats_df = pd.read_csv(os.path.join(log_folder, \"llm_stats.csv\"), sep=\",\")\n",
    "stats_df.head()\n",
    "\n",
    "stats_df['datetime'] = pd.to_datetime(stats_df['simulation_time'], unit='s')\n",
    "# stats_df = stats_df[stats_df['datetime'] < datetime.datetime(2025, 5, 31)]\n",
    "stats_df['date'] = stats_df['datetime'].dt.floor('24H')\n",
    "# print(stats_df[stats_df['date'] == datetime.datetime(2025, 5, 23)].head())\n",
    "\n",
    "all_files = stats_df['content_file'].unique()\n",
    "# all_files = [os.path.join(log_folder, \"chat_logs\", file) for file in all_files]\n",
    "\n",
    "def get_json_part(text: str) -> str:\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "    if start == -1 or end == -1:\n",
    "        return None\n",
    "    return text[start:end + 1]\n",
    "\n",
    "def get_reason(file):\n",
    "    try:\n",
    "        file_path = os.path.join(log_folder, \"chat_logs\", file)\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            if \"### travel.plan\" not in content:\n",
    "                return None\n",
    "            resp = content.split(\"Response: \")[1].split(\"------\")[0]\n",
    "            # json_part = get_json_part(resp)\n",
    "            # json_data = json.loads(json_part)\n",
    "            choice = int(resp.split('\"chosen_plan\":')[1].split(\",\")[0])\n",
    "            reason = resp.split('\"reason\":')[1].replace('\"', '').split(\"}\")[0].strip()\n",
    "            if \"because it\" in reason:\n",
    "                reason = reason.split(\"because it\")[1].strip()\n",
    "            return reason\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "        return 0\n",
    "    \n",
    "def extract_history(file):\n",
    "    try:\n",
    "        file_path = os.path.join(log_folder, \"chat_logs\", file)\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            if \"### travel.plan\" not in content:\n",
    "                return None\n",
    "            if \"The related travel histories that support your decision are:\" not in content:\n",
    "                return None\n",
    "            resp = content.split(\"The related travel histories that support your decision are:\")[1]\\\n",
    "                    .split(\"You should consider the following factors:\")[0]\n",
    "            return resp.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "        return None\n",
    "\n",
    "_m = {\n",
    "    f: get_reason(f) for f in all_files\n",
    "}\n",
    "stats_df['reason'] = stats_df['content_file'].map(_m)\n",
    "\n",
    "_m = {\n",
    "    f: extract_history(f) for f in all_files\n",
    "}\n",
    "stats_df['history'] = stats_df['content_file'].map(_m)\n",
    "\n",
    "stats_df = stats_df[stats_df['history'].notna()]\n",
    "\n",
    "# print(stats_df.head())\n",
    "\n",
    "stop_word_list = set(stopwords.words('english'))\n",
    "def jaccard_similarity(text1_list, text2):\n",
    "    all_ = []\n",
    "    for text1 in text1_list:\n",
    "        # set1 = set(text1.split())\n",
    "        # set2 = set(text2.split())\n",
    "        set1 = set(word_tokenize(text1.lower())) - stop_word_list\n",
    "        set2 = set(word_tokenize(text2.lower())) - stop_word_list\n",
    "        intersection = set1.intersection(set2)\n",
    "        union = set1.union(set2)\n",
    "        all_.append(len(intersection) / len(union))\n",
    "    return max(all_) if all_ else 0\n",
    "\n",
    "def jaccard_similarity_ner(text1_list, text2):\n",
    "    all_ = []\n",
    "    for text1 in text1_list:\n",
    "        set1 = set([ent.text for ent in nlp(text1).ents])\n",
    "        set2 = set([ent.text for ent in nlp(text2).ents])\n",
    "        intersection = set1.intersection(set2)\n",
    "        union = set1.union(set2)\n",
    "        all_.append(len(intersection) / len(union))\n",
    "    return max(all_) if all_ else 0\n",
    "\n",
    "# stats_df['history_similarity'] = stats_df.apply(\n",
    "#     lambda row: jaccard_similarity(row['history'].split(\"\\n\"), row['reason']),\n",
    "#     axis=1\n",
    "# )\n",
    "# print(stats_df['history_similarity'].describe())\n",
    "\n",
    "def count_mentioned_terms(text):\n",
    "    terms = [\"short\", \"quick\", \"fast\"]\n",
    "    count = 0\n",
    "    for term in terms:\n",
    "        count += text.lower().count(term)\n",
    "    return count\n",
    "\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_similarities(sentence1_list, sentence2):\n",
    "    all_ = []\n",
    "    for sentence1 in sentence1_list:\n",
    "        ref = [word_tokenize(sentence1.lower())]\n",
    "        cand = word_tokenize(sentence2.lower())\n",
    "        smoothie = SmoothingFunction().method2\n",
    "        bleu = sentence_bleu(ref, cand, smoothing_function=smoothie)\n",
    "        all_.append(bleu)\n",
    "\n",
    "    return max(all_) if all_ else 0\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "stats_df = stats_df[(stats_df['date'] <= datetime.datetime(2025, 5, 16)) & (stats_df['date'] >= datetime.datetime(2025, 5, 12))]\n",
    "\n",
    "# stats_df['bleu_similarity'] = stats_df.progress_apply(\n",
    "#     lambda row: calculate_similarities(row['history'].split(\"\\n\"), row['reason']),\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# sns.boxplot(x='date', y='bleu_similarity', data=stats_df, showfliers=False, palette='crest')\n",
    "# plt.title('Jaccard Similarity of Experiences and Reasoning Over Time')\n",
    "# plt.ylabel('Jaccard Value')\n",
    "# plt.xlabel('Date')\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "stats_df['num_mentioned_terms'] = stats_df['reason'].progress_apply(\n",
    "    lambda x: count_mentioned_terms(x)\n",
    ")\n",
    "\n",
    "for text in stats_df[(stats_df['num_mentioned_terms'] == 0) & (stats_df['date'] ==  datetime.datetime(2025, 5, 15))][\"reason\"].head(100):\n",
    "    print(text)\n",
    "\n",
    "# Calculate ratio of num_mentioned_terms == 0 per date\n",
    "zero_terms_ratio = stats_df.groupby('date').apply(\n",
    "    lambda x: (x['num_mentioned_terms'] > 0).sum() / len(x)\n",
    ").reset_index(name='ratio_zero_terms')\n",
    "# Highlight points where ratio_zero_terms < 0.85 in red\n",
    "highlight = zero_terms_ratio['date'].isin([\n",
    "    datetime.datetime(2025, 5, 17),\n",
    "    datetime.datetime(2025, 5, 18),\n",
    "    datetime.datetime(2025, 5, 24),\n",
    "    datetime.datetime(2025, 5, 25),\n",
    "    datetime.datetime(2025, 5, 31)\n",
    "])\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.lineplot(x='date', y='ratio_zero_terms', data=zero_terms_ratio, marker='o')\n",
    "plt.scatter(\n",
    "    zero_terms_ratio.loc[highlight, 'date'],\n",
    "    zero_terms_ratio.loc[highlight, 'ratio_zero_terms'],\n",
    "    color='red',\n",
    "    zorder=10,\n",
    "    label='Low ratio'\n",
    ")\n",
    "plt.title('Ratio of the number of decisions that rely on the shortest path')\n",
    "plt.ylabel('Ratio of decisions')\n",
    "plt.xlabel('Date')\n",
    "plt.xticks(rotation=90)\n",
    "plt.gca().set_xticks(result['date'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60764be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# People choose suboptimal route over time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "# Mode Shape per timestep\n",
    "\n",
    "stats_df = pd.read_csv(os.path.join(log_folder, \"llm_stats.csv\"), sep=\",\")\n",
    "stats_df.head()\n",
    "\n",
    "all_files = stats_df['content_file'].unique()\n",
    "# all_files = [os.path.join(log_folder, \"chat_logs\", file) for file in all_files]\n",
    "\n",
    "def get_json_part(text: str) -> str:\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\")\n",
    "    if start == -1 or end == -1:\n",
    "        return None\n",
    "    return text[start:end + 1]\n",
    "\n",
    "def check_suboptimal_choice(file):\n",
    "    try:\n",
    "        file_path = os.path.join(log_folder, \"chat_logs\", file)\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            if \"### travel.plan\" not in content:\n",
    "                return 0\n",
    "            resp = content.split(\"Response: \")[1].split(\"------\")[0]\n",
    "            # json_part = get_json_part(resp)\n",
    "            # json_data = json.loads(json_part)\n",
    "            choice = int(resp.split('\"chosen_plan\":')[1].split(\",\")[0])\n",
    "            # suboptimal = json_data[\"chosen_plan\"] != 1\n",
    "            suboptimal = choice != 1\n",
    "            return 1 if suboptimal else -1\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "        return 0\n",
    "\n",
    "_m = {\n",
    "    f: check_suboptimal_choice(f) for f in all_files\n",
    "}\n",
    "\n",
    "stats_df['suboptimal_choice'] = stats_df['content_file'].map(_m)\n",
    "print(stats_df.head())\n",
    "# stats_df['suboptimal_choice'].describe()\n",
    "\n",
    "df = stats_df[stats_df['suboptimal_choice'] != 0]\n",
    "# count number of suboptimal choices and total choices over time windows of 24 hours\n",
    "df['datetime'] = pd.to_datetime(df['simulation_time'], unit='s')\n",
    "df = df[df['datetime'] < datetime.datetime(2025, 5, 17)]\n",
    "df['time_bin'] = df['datetime'].dt.floor('24H')\n",
    "\n",
    "data = df.groupby(['time_bin']).agg(\n",
    "    suboptimal_count=('suboptimal_choice', lambda x: (x == 1).sum()),\n",
    "    total_count=('suboptimal_choice', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# ratio of suboptimal choices\n",
    "data['ratio'] = (data['suboptimal_count'] / data['total_count']) * 100\n",
    "data\n",
    "\n",
    "sns.set_theme(style=\"ticks\")\n",
    "# Draw the graph of ratio\n",
    "plt.figure(figsize=(8, 5))\n",
    "# plt.bar(data['time_bin'], data['ratio'], color='skyblue')\n",
    "sns.barplot(\n",
    "    data=data, \n",
    "    x='time_bin', \n",
    "    y='ratio',\n",
    "    # palette='mako',\n",
    "    color=\"#1f77b4\",\n",
    "    edgecolor='black'\n",
    ")\n",
    "plt.title('Percentage of Suboptimal Route Choice by Day')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Suboptimal Choice Percentage (%)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
